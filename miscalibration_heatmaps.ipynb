{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MA heatmap for Scenarios 1 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# data\n",
    "models = ['bnn_mcd', 'bnn_dc', 'mdn', 'ens_nn', 'rnn']\n",
    "scenarios = ['Random', 'WD', 'OOD']\n",
    "variables = ['aph_443', 'aph_675', 'aCDOM_443', 'aCDOM_675', 'aNAP_443', 'aNAP_675']\n",
    "variables_formatted = ['a$_{ph}$\\n(443)', 'a$_{ph}$\\n(675)', 'a$_{CDOM}$\\n(443)', 'a$_{CDOM}$\\n(675)', 'a$_{NAP}$\\n(443)', 'a$_{NAP}$\\n(675)']\n",
    "model_file_mapping = {\n",
    "    'BNN MCD': 'bnn_mcd',\n",
    "    'BNN DC': 'bnn_dc',\n",
    "    'MDN': 'mdn',\n",
    "    'ENS NN': 'ens_nn',\n",
    "    'RNN': 'rnn'\n",
    "}\n",
    "\n",
    "def get_median_model_ma(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if 'model' not in df.columns or 'MdSA' not in df.columns:\n",
    "            print(f\"Required columns not found in {file_path}\")\n",
    "            return [np.nan] * len(variables)\n",
    "\n",
    "        # group by model and get the median MdSA\n",
    "        median_mdsa = df.groupby('model')['MdSA'].median().sort_values()\n",
    "        if len(median_mdsa) == 0:\n",
    "            print(f\"No valid data found in {file_path}\")\n",
    "            return [np.nan] * len(variables)\n",
    "\n",
    "        median_model = median_mdsa.index[len(median_mdsa) // 2]  # get the middle model\n",
    "        median_model_data = df[df['model'] == median_model]\n",
    "        \n",
    "        # get MA values for each variable\n",
    "        ma_values = []\n",
    "        for var in variables:\n",
    "            var_data = median_model_data[median_model_data['variable'] == var]\n",
    "            if len(var_data) > 0:\n",
    "                ma_values.append(var_data['MA'].iloc[0])\n",
    "            else:\n",
    "                ma_values.append(np.nan)\n",
    "        return ma_values\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return [np.nan] * len(variables)\n",
    "\n",
    "def process_data(base_path):\n",
    "    # before/without recal\n",
    "    # after/with recal\n",
    "    before_data = np.zeros((len(models), len(scenarios), len(variables)))\n",
    "    after_data = np.zeros((len(models), len(scenarios), len(variables)))\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        for j, scenario in enumerate(scenarios):\n",
    "            before_file = os.path.join(base_path, f'{model}_{scenario}_split_metrics.csv')\n",
    "            after_file = os.path.join(base_path, f'{model}_{scenario}_split_recal_metrics.csv')\n",
    "            \n",
    "            if not os.path.exists(before_file):\n",
    "                print(f\"File not found: {before_file}\")\n",
    "                before_data[i, j] = [np.nan] * len(variables)\n",
    "            else:\n",
    "                before_data[i, j] = get_median_model_ma(before_file)\n",
    "            \n",
    "            if not os.path.exists(after_file):\n",
    "                print(f\"File not found: {after_file}\")\n",
    "                after_data[i, j] = [np.nan] * len(variables)\n",
    "            else:\n",
    "                after_data[i, j] = get_median_model_ma(after_file)\n",
    "\n",
    "    return before_data, after_data\n",
    "\n",
    "# process the datasets\n",
    "base_path = r'C:\\SwitchDrive\\Data\\pnn_model_estimates'\n",
    "before_data, after_data = process_data(base_path)\n",
    "# change/difference \n",
    "change_data = after_data - before_data\n",
    "\n",
    "def plot_heatmap(data, ax, title, cmap, vmin, vmax, center=None, cbar_ax=None, ylabel=True, xlabel=False):\n",
    "    sns.heatmap(data, ax=ax, cmap=cmap, annot=True, fmt='.3f', \n",
    "                xticklabels=variables_formatted if xlabel else False, \n",
    "                yticklabels=scenarios if ylabel else False, \n",
    "                cbar=cbar_ax is not None, cbar_ax=cbar_ax, vmin=vmin, vmax=vmax, center=center)\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=16, fontweight='bold')\n",
    "    if xlabel:\n",
    "        ax.set_xticks(np.arange(len(variables)) + 0.5)\n",
    "        ax.set_xticklabels(variables_formatted)\n",
    "    ax.set_xlabel('')\n",
    "    if not ylabel:\n",
    "        ax.set_ylabel('')\n",
    "\n",
    "# start the plotting here\n",
    "fig, axs = plt.subplots(5, 3, figsize=(16, 14))\n",
    "\n",
    "# calculate global min and max for consistent color scaling\n",
    "#global_min = np.nanmin([np.nanmin(before_data), np.nanmin(after_data)])\n",
    "#global_max = np.nanmax([np.nanmax(before_data), np.nanmax(after_data)])\n",
    "#change_abs_max = np.nanmax([abs(np.nanmin(change_data)), abs(np.nanmax(change_data))])\n",
    "\n",
    "# tick ranges\n",
    "ticks_before_after = np.linspace(0, 0.45, 9)\n",
    "ticks_change = np.linspace(-0.4, 0.4, 9)\n",
    "# add a zero to the difference cbar\n",
    "ticks_change = np.append(ticks_change, 0)\n",
    "ticks_change = np.sort(ticks_change)\n",
    "\n",
    "# cbars positioning\n",
    "cbar_before_after = fig.add_axes([0.9, 0.3, 0.015, 0.4])\n",
    "cbar_change = fig.add_axes([0.97, 0.3, 0.015, 0.4])\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    display_name = [name for name, file in model_file_mapping.items() if file == model][0]\n",
    "    plot_heatmap(before_data[i], axs[i, 0], None, 'cividis', 0, 0.45, cbar_ax=cbar_before_after if i == 0 else None)\n",
    "    plot_heatmap(after_data[i], axs[i, 1], display_name if i == 0 else None, 'cividis', 0, 0.45, ylabel=False)\n",
    "    plot_heatmap(change_data[i], axs[i, 2], None, 'BrBG_r', -0.4, 0.4, center=0, cbar_ax=cbar_change if i == 0 else None, ylabel=False)\n",
    "    if i < 4:  # remove x-axis labels but for last row\n",
    "        for j in range(3):\n",
    "            axs[i, j].set_xticklabels([])\n",
    "\n",
    "    if i == 4:  # x-axis labels just for the last row\n",
    "        for j in range(3):\n",
    "            axs[i, j].set_xticks(np.arange(len(variables)) + 0.5)\n",
    "            axs[i, j].set_xticklabels(variables_formatted)\n",
    "\n",
    "    # model title to the middle column of each row\n",
    "    axs[i, 1].set_title(display_name, fontsize=14, fontweight='bold')\n",
    "\n",
    "# adjustments colorbar ticks and labels\n",
    "cbar_before_after.set_ylabel('Mis-calibration area', fontsize=10, fontweight='bold')\n",
    "cbar_before_after.set_title('With/without\\nrecalibration', fontsize=10, fontweight='bold')\n",
    "cbar_before_after.yaxis.set_ticks(ticks_before_after)\n",
    "cbar_before_after.yaxis.set_ticklabels([f'{x:.2f}' for x in ticks_before_after])\n",
    "\n",
    "cbar_change.set_ylabel('Mis-calibration area difference', fontsize=10, fontweight='bold')\n",
    "cbar_change.set_title('Calibration\\ndifference', fontsize=10, fontweight='bold')\n",
    "cbar_change.yaxis.set_ticks(ticks_change)\n",
    "cbar_change.yaxis.set_ticklabels([f'{x:.2f}' for x in ticks_change])\n",
    "\n",
    "# titles for the three columns\n",
    "fig.text(0.17, 0.95, 'Without recalibration', ha='center', fontsize=14, fontweight='bold')\n",
    "fig.text(0.45, 0.95, 'With recalibration', ha='center', fontsize=14, fontweight='bold')\n",
    "fig.text(0.73, 0.95, 'Calibration difference', ha='center', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.88, 0.95])\n",
    "#plt.savefig('C:/SwitchDrive/Data/Plots/miscalibration_s1-3.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adjusted for PRISMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dupdated variables\n",
    "models = ['bnn_mcd', 'bnn_dc', 'mdn', 'ens_nn', 'rnn']\n",
    "scenarios = ['prisma_1', 'prisma_ood_a', 'prisma_ood_l', 'prisma_wd_a', 'prisma_wd_l']\n",
    "new_y_labels = ['Subscenario 1', 'Subscenario 2:\\nACOLITE', 'Subscenario 2:\\nL2', 'Subscenario 3:\\nACOLITE', 'Subscenario 3:\\nL2']\n",
    "variables = ['aph_443', 'aph_675', 'aCDOM_443', 'aCDOM_675', 'aNAP_443', 'aNAP_675']\n",
    "variables_formatted = ['a$_{ph}$\\n(443)', 'a$_{ph}$\\n(675)', 'a$_{CDOM}$\\n(443)', 'a$_{CDOM}$\\n(675)', 'a$_{NAP}$\\n(443)', 'a$_{NAP}$\\n(675)']\n",
    "model_file_mapping = {\n",
    "    'BNN MCD': 'bnn_mcd',\n",
    "    'BNN DC': 'bnn_dc',\n",
    "    'MDN': 'mdn',\n",
    "    'ENS NN': 'ens_nn',\n",
    "    'RNN': 'rnn'\n",
    "}\n",
    "\n",
    "# process\n",
    "base_path = r'C:\\SwitchDrive\\Data\\pnn_model_estimates'\n",
    "before_data, after_data = process_data(base_path)\n",
    "change_data = after_data - before_data\n",
    "\n",
    "def plot_heatmap(data, ax, title, cmap, vmin, vmax, center=None, cbar_ax=None, ylabel=True, xlabel=False):\n",
    "    sns.heatmap(data, ax=ax, cmap=cmap, annot=True, fmt='.3f', \n",
    "                xticklabels=variables_formatted if xlabel else False, \n",
    "                # update:\n",
    "                yticklabels=new_y_labels if ylabel else False, \n",
    "                cbar=cbar_ax is not None, cbar_ax=cbar_ax, vmin=vmin, vmax=vmax, center=center)\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('')\n",
    "    if not ylabel:\n",
    "        ax.set_ylabel('')\n",
    "\n",
    "fig, axs = plt.subplots(5, 3, figsize=(16, 14))\n",
    "\n",
    "#global_min = np.nanmin([np.nanmin(before_data), np.nanmin(after_data)])\n",
    "#global_max = np.nanmax([np.nanmax(before_data), np.nanmax(after_data)])\n",
    "#change_abs_max = np.nanmax([abs(np.nanmin(change_data)), abs(np.nanmax(change_data))])\n",
    "\n",
    "ticks_before_after = np.linspace(0, 0.4, 10)\n",
    "ticks_change = np.linspace(-0.3, 0.3, 9)\n",
    "ticks_change = np.append(ticks_change, 0)\n",
    "ticks_change = np.sort(ticks_change)\n",
    "\n",
    "cbar_before_after = fig.add_axes([0.9, 0.3, 0.015, 0.4])\n",
    "cbar_change = fig.add_axes([0.97, 0.3, 0.015, 0.4])\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    display_name = [name for name, file in model_file_mapping.items() if file == model][0]\n",
    "    plot_heatmap(before_data[i], axs[i, 0], None, 'cividis', 0, 0.4, cbar_ax=cbar_before_after if i == 0 else None)\n",
    "    plot_heatmap(after_data[i], axs[i, 1], display_name if i == 0 else None, 'cividis', 0, 0.45, ylabel=False)\n",
    "    plot_heatmap(change_data[i], axs[i, 2], None, 'BrBG_r', -0.3, 0.3, center=0, cbar_ax=cbar_change if i == 0 else None, ylabel=False)\n",
    "    if i < 4:\n",
    "        for j in range(3):\n",
    "            axs[i, j].set_xticklabels([])\n",
    "\n",
    "    if i == 4:\n",
    "        for j in range(3):\n",
    "            axs[i, j].set_xticks(np.arange(len(variables)) + 0.5)\n",
    "            axs[i, j].set_xticklabels(variables_formatted)\n",
    "\n",
    "    axs[i, 1].set_title(display_name, fontsize=14, fontweight='bold')\n",
    "\n",
    "cbar_before_after.set_ylabel('Mis-calibration area', fontsize=10, fontweight='bold')\n",
    "cbar_before_after.set_title('With/without\\nrecalibration', fontsize=10, fontweight='bold')\n",
    "cbar_before_after.yaxis.set_ticks(ticks_before_after)\n",
    "cbar_before_after.yaxis.set_ticklabels([f'{x:.2f}' for x in ticks_before_after])\n",
    "# somehow shows no effect, not sure how to have the extend='max' active\n",
    "cbar_before_after.extend = 'max'\n",
    "\n",
    "cbar_change.set_ylabel('Mis-calibration area difference', fontsize=10, fontweight='bold')\n",
    "cbar_change.set_title('Calibration\\ndifference', fontsize=10, fontweight='bold')\n",
    "cbar_change.yaxis.set_ticks(ticks_change)\n",
    "cbar_change.yaxis.set_ticklabels([f'{x:.2f}' for x in ticks_change])\n",
    "\n",
    "fig.text(0.21, 0.95, 'Without recalibration', ha='center', fontsize=14, fontweight='bold')\n",
    "fig.text(0.475, 0.95, 'With recalibration', ha='center', fontsize=14, fontweight='bold')\n",
    "fig.text(0.745, 0.95, 'Calibration difference', ha='center', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.88, 0.95])\n",
    "#plt.savefig('C:/SwitchDrive/Data/Plots/miscalibration_prisma.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysis of the heatmaps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subscenario 1 - All:\n",
      "Number of cases where recalibration was beneficial: 19\n",
      "Average improvement when beneficial: -0.1153\n",
      "Median improvement when beneficial: -0.0910\n",
      "Percentage of cases where recalibration was beneficial: 63.33%\n",
      "\n",
      "\n",
      "Subscenario 2 - ACOLITE:\n",
      "Number of cases where recalibration was beneficial: 20\n",
      "Average improvement when beneficial: -0.0934\n",
      "Median improvement when beneficial: -0.0870\n",
      "Percentage of cases where recalibration was beneficial: 66.67%\n",
      "\n",
      "\n",
      "Subscenario 2 - L2:\n",
      "Number of cases where recalibration was beneficial: 20\n",
      "Average improvement when beneficial: -0.1571\n",
      "Median improvement when beneficial: -0.1525\n",
      "Percentage of cases where recalibration was beneficial: 66.67%\n",
      "\n",
      "\n",
      "Subscenario 3 - ACOLITE:\n",
      "Number of cases where recalibration was beneficial: 23\n",
      "Average improvement when beneficial: -0.1195\n",
      "Median improvement when beneficial: -0.1410\n",
      "Percentage of cases where recalibration was beneficial: 76.67%\n",
      "\n",
      "\n",
      "Subscenario 3 - L2:\n",
      "Number of cases where recalibration was beneficial: 17\n",
      "Average improvement when beneficial: -0.1066\n",
      "Median improvement when beneficial: -0.1000\n",
      "Percentage of cases where recalibration was beneficial: 56.67%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calibration difference values for PRISMA subscenarios\n",
    "calibration_diff = [\n",
    "    [-0.007, -0.092, 0.134, -0.210, -0.100, -0.195],\n",
    "    [-0.069, -0.127, 0.186, -0.164, -0.030, -0.210],\n",
    "    [-0.138, -0.124, 0.094, -0.146, -0.159, -0.261],\n",
    "    [-0.144, -0.195, -0.012, -0.174, -0.238, -0.172],\n",
    "    [-0.151, -0.170, -0.100, -0.211, -0.219, -0.166],\n",
    "    [-0.078, -0.218, 0.116, -0.186, -0.091, -0.181],\n",
    "    [-0.026, -0.129, 0.112, -0.098, -0.044, -0.153],\n",
    "    [-0.245, -0.112, 0.092, -0.199, -0.030, -0.283],\n",
    "    [-0.141, -0.146, -0.080, -0.151, -0.189, -0.210],\n",
    "    [-0.037, -0.037, -0.016, -0.126, -0.080, -0.070],\n",
    "    [0.048, -0.081, 0.068, -0.055, -0.215, -0.235],\n",
    "    [0.091, -0.002, 0.128, -0.150, -0.076, -0.110],\n",
    "    [-0.253, -0.202, 0.028, -0.119, -0.118, -0.211],\n",
    "    [-0.055, -0.163, 0.122, -0.122, -0.100, -0.121],\n",
    "    [0.103, 0.041, 0.126, 0.047, 0.160, 0.188],\n",
    "    [0.092, -0.060, 0.125, -0.038, 0.079, -0.054],\n",
    "    [0.014, -0.074, 0.137, -0.073, 0.190, 0.013],\n",
    "    [0.023, 0.110, 0.187, -0.160, 0.143, -0.106],\n",
    "    [-0.006, 0.050, 0.027, -0.162, -0.030, -0.039],\n",
    "    [0.030, 0.038, 0.079, -0.176, -0.005, -0.104],\n",
    "    [0.074, 0.023, 0.129, -0.079, 0.078, -0.016],\n",
    "    [-0.003, 0.004, 0.077, -0.133, -0.008, -0.189],\n",
    "    [0.075, -0.001, 0.159, -0.165, 0.079, -0.110],\n",
    "    [0.076, 0.109, -0.001, -0.098, 0.074, 0.116],\n",
    "    [0.023, -0.051, -0.094, 0.042, 0.026, 0.110]\n",
    "]\n",
    "\n",
    "def analyze_subset(data, subscenario, method):\n",
    "    flat_data = [item for sublist in data for item in sublist]\n",
    "    # negative differences are beneficial recalibrations\n",
    "    beneficial_recalibrations = [x for x in flat_data if x < 0]\n",
    "    # how many are beneficial\n",
    "    count_beneficial = len(beneficial_recalibrations)\n",
    "    total_improvement = sum(beneficial_recalibrations)\n",
    "    # what's the average improvement through recal if effective\n",
    "    average_improvement = total_improvement / count_beneficial if count_beneficial > 0 else 0\n",
    "    # and the median\n",
    "    median_improvement = np.median(beneficial_recalibrations) if count_beneficial > 0 else 0\n",
    "    total_cases = len(flat_data)\n",
    "    # percent beneficial\n",
    "    percentage_beneficial = (count_beneficial / total_cases) * 100\n",
    "    print(f\"Subscenario {subscenario} - {method}:\")\n",
    "    print(f\"Number of cases where recalibration was beneficial: {count_beneficial}\")\n",
    "    print(f\"Average improvement when beneficial: {average_improvement:.4f}\")\n",
    "    print(f\"Median improvement when beneficial: {median_improvement:.4f}\")\n",
    "    print(f\"Percentage of cases where recalibration was beneficial: {percentage_beneficial:.2f}%\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# subscenario 1 (rows 1, 6, 11, 16, 21)\n",
    "subscenario_1 = [calibration_diff[i] for i in [0, 5, 10, 15, 20]]\n",
    "analyze_subset(subscenario_1, 1, \"All\")\n",
    "\n",
    "# subscenario 2 ACOLITE (rows 2, 7, 12, 17, 22)\n",
    "subscenario_2_acolite = [calibration_diff[i] for i in [1, 6, 11, 16, 21]]\n",
    "analyze_subset(subscenario_2_acolite, 2, \"ACOLITE\")\n",
    "\n",
    "# subscenario 2 L2 (rows 3, 8, 13, 18, 23)\n",
    "subscenario_2_l2 = [calibration_diff[i] for i in [2, 7, 12, 17, 22]]\n",
    "analyze_subset(subscenario_2_l2, 2, \"L2\")\n",
    "\n",
    "# subscenario 3 ACOLITE (rows 4, 9, 14, 19, 24)\n",
    "subscenario_3_acolite = [calibration_diff[i] for i in [3, 8, 13, 18, 23]]\n",
    "analyze_subset(subscenario_3_acolite, 3, \"ACOLITE\")\n",
    "\n",
    "# subscenario 3 L2 (rows 5, 10, 15, 20, 25)\n",
    "subscenario_3_l2 = [calibration_diff[i] for i in [4, 9, 14, 19, 24]]\n",
    "analyze_subset(subscenario_3_l2, 3, \"L2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario: Random\n",
      "Number of cases where recalibration was beneficial: 30\n",
      "Average improvement when beneficial: -0.1208\n",
      "Median improvement when beneficial: -0.1245\n",
      "Percentage of cases where recalibration was beneficial: 100.00%\n",
      "\n",
      "\n",
      "Scenario: WD\n",
      "Number of cases where recalibration was beneficial: 26\n",
      "Average improvement when beneficial: -0.1724\n",
      "Median improvement when beneficial: -0.1490\n",
      "Percentage of cases where recalibration was beneficial: 86.67%\n",
      "\n",
      "\n",
      "Scenario: OOD\n",
      "Number of cases where recalibration was beneficial: 14\n",
      "Average improvement when beneficial: -0.0809\n",
      "Median improvement when beneficial: -0.0675\n",
      "Percentage of cases where recalibration was beneficial: 46.67%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_data(heatmap, row_indices):\n",
    "    return [heatmap[i] for i in row_indices]\n",
    "\n",
    "def analyze_subset(data, scenario):\n",
    "    flat_data = [item for sublist in data for item in sublist]\n",
    "    beneficial_recalibrations = [x for x in flat_data if x < 0]\n",
    "    count_beneficial = len(beneficial_recalibrations)\n",
    "    total_improvement = sum(beneficial_recalibrations)\n",
    "    average_improvement = total_improvement / count_beneficial if count_beneficial > 0 else 0\n",
    "    median_improvement = np.median(beneficial_recalibrations) if count_beneficial > 0 else 0\n",
    "    total_cases = len(flat_data)\n",
    "    percentage_beneficial = (count_beneficial / total_cases) * 100\n",
    "\n",
    "    return {\n",
    "        \"scenario\": scenario,\n",
    "        \"count_beneficial\": count_beneficial,\n",
    "        \"average_improvement\": average_improvement,\n",
    "        \"median_improvement\": median_improvement,\n",
    "        \"percentage_beneficial\": percentage_beneficial,\n",
    "    }\n",
    "\n",
    "# scenarios 1-3\n",
    "heatmap = [\n",
    "    [-0.159, -0.183, -0.162, -0.208, -0.163, -0.167],\n",
    "    [-0.219, -0.227, -0.126, -0.208, -0.144, -0.154],\n",
    "    [-0.062, -0.030, -0.094, -0.129, -0.045, -0.252],\n",
    "    [-0.108, -0.121, -0.108, -0.142, -0.096, -0.128],\n",
    "    [-0.157, -0.123, -0.037, -0.140, -0.078, -0.117],\n",
    "    [0.062, 0.058, 0.042, -0.041, 0.051, -0.046],\n",
    "    [-0.164, -0.177, -0.149, -0.248, -0.155, -0.103],\n",
    "    [-0.108, -0.126, -0.168, -0.180, -0.143, -0.135],\n",
    "    [0.036, 0.032, -0.090, -0.073, 0.095, -0.148],\n",
    "    [-0.101, -0.081, -0.080, -0.154, -0.055, -0.079],\n",
    "    [-0.264, -0.232, -0.361, -0.316, -0.242, -0.334],\n",
    "    [0.150, 0.096, 0.093, 0.034, 0.162, 0.035],\n",
    "    [-0.038, -0.054, -0.008, -0.138, -0.053, -0.042],\n",
    "    [0.041, -0.016, 0.088, -0.128, 0.005, 0.032],\n",
    "    [0.083, 0.043, -0.025, -0.073, 0.138, -0.025]\n",
    "]\n",
    "\n",
    "# run\n",
    "random_data = extract_data(heatmap, [0, 3, 6, 9, 12])\n",
    "wd_data = extract_data(heatmap, [1, 4, 7, 10, 13])\n",
    "ood_data = extract_data(heatmap, [2, 5, 8, 11, 14])\n",
    "\n",
    "results = []\n",
    "for scenario, data in [(\"Random\", random_data), (\"WD\", wd_data), (\"OOD\", ood_data)]:\n",
    "    results.append(analyze_subset(data, scenario))\n",
    "\n",
    "# print outcomes\n",
    "for result in results:\n",
    "    print(f\"Scenario: {result['scenario']}\")\n",
    "    print(f\"Number of cases where recalibration was beneficial: {result['count_beneficial']}\")\n",
    "    print(f\"Average improvement when beneficial: {result['average_improvement']:.4f}\")\n",
    "    print(f\"Median improvement when beneficial: {result['median_improvement']:.4f}\")\n",
    "    print(f\"Percentage of cases where recalibration was beneficial: {result['percentage_beneficial']:.2f}%\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
